---
title: Machine-Retaylored Albums?
categories:
- General
feature_image: "https://picsum.photos/2560/600?image=872"
---

As a finale of our [Taylor Series](https://mathworld.wolfram.com/TaylorSeries.html), we want to classify all tracks into their respective albums. Our scope is the all standard tracks until from `Taylor Swfit` to `evermore`. With that, we will use the audio features from Spotify, the songwriting credits, and the created lexical ratios based on our [first blog](https://sonic-edgehog.github.io/general/2021/04/04/ts-blog-001/). For the full codes and implementation, see the corresponding notebook `ts_liners.ipynb` in the [codes](https://github.com/sonic-edgehog/sonic-edgehog.github.io/tree/main/codes) folder.

{% include lib/mathjax.html %}

## Exploring the dataset

We join the songwriting credits, stanzas, and sound from her discography. Since our credits data are listed according to the names, we convert them into a series of binary vectors through [one hot encoding](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html). It is done for the algorithm to read it better as values instead of names.

{% include ts_lyrics_tsne_lda.html %}

```python
ts_lyric_sound_combined['track_5'] = np.where(ts_lyric_sound_combined['track_number'] == 5, 1, 0)
```

To ensure that our model will be too biased towards some features due to magnitudes, we standardized them. The code block is used below.

```python
from sklearn.preprocessing import StandardScaler
ts_lyric_sound_standard[new_features] = StandardScaler().fit_transform(ts_lyric_sound_standard[new_features])
```

To check how the distributions of the respective features could affect our model, we graph them. We excluded the `instrumentalness` feature since it has **57** values of **0**.


{% include ts_combi_distribution.html %}

**Figure 1.** `Valence`, `tempo`, and `lexical uniqueness` have similar distributions.

Finally, we used heatmaps to graph the difference in correlation matrices between the two classes. In our dataset, we have **128** non-Track Fives and **9** Track Fives.


{% include ts_combi_heatmap_track5.html %}

**Figure 2.** The correlations between `speechiness` and **7** other features are negatively associated.

It seems that the the fifth tracks have shown better association among the features compared to the other tracks. As shown in our table below, the column with the lowest track `valence` per album is comprised of mostly track fives.


{% include taylor_table_low_sound.html %}

**Table 1.** Seven out of nine Track Five songs occupied **12** of the seventy-two positions.


{% include ts_combi_heatmap_notrack5.html %}

**Figure 2.** Almost half of the correlations are below the absolute value of **0.10**.

## Taylor Swift (Achromantic's Version)

As we re-record the songs and re-arrange as what the machine has intended, here are the following combinations of those album based on the predicted probabilities. In our case, we will include the misclassified track as part of the album only if none of the first three predicted labels are the same with the actual label.

[H2o package](https://www.h2o.ai/) is an open source model building and optimization. We will use it to run a classification model and find the most important features. In particular, we will use Random Forest with the package `H2ORandomForestEstimator`. Since the model runs only with `h2oframe`, we convert it first by using `h2o.H2OFrame` and as for the label, we convert it into factor by using the `asfactor` function.

In separating the training dataset form the testing dataset, we include all tracks from the first album to `reputation` and first few tracks in `Lover`. The testing dataset will be the rest of the discography. 

|                	| Training 	| Testing 	|
|----------------	|----------	|---------	|
| Track Five     	| 7        	| 2       	|
| Non-Track Five 	| 90       	| 38      	|

**Table 2.**  The dataset is split into **71-29**.

To run the model, we have to put the predictors and the response based on our features in the `h2oframe`.

```python
predictor = new_features
response = "track_5"
ts_model = H2ORandomForestEstimator(ntrees=50, max_depth=20, nfolds=10,balance_classes = True,seed=42)
ts_model.train(x = predictor, y = response, training_frame = ts_df_train)
